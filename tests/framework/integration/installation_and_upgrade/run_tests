#!/bin/bash -ex

spacelist_to_commalist() {
    echo $@ | tr ' ' ','
}

# shellcheck source=tests/framework/integration/utils/node_lib.sh
. "$CHROMA_DIR"/tests/framework/integration/utils/node_lib.sh

[ -r localenv ] && . localenv

# Remove test results and coverage reports from previous run
rm -rfv $PWD/test_reports/*
rm -rfv $PWD/coverage_reports/.coverage*
mkdir -p $PWD/test_reports
mkdir -p $PWD/coverage_reports

ARCHIVE_NAME=$SHORT_ARCHIVE_NAME-$IEEL_VERSION-current.tar.gz
CLUSTER_CONFIG=${CLUSTER_CONFIG:-"$(ls $PWD/shared_storage_configuration_cluster_cfg.json)"}
CHROMA_DIR=${CHROMA_DIR:-"$PWD/integrated-manager-for-lustre/"}
USE_FENCE_XVM=false

PREVIOUS_INSTALL_DIR=previous_install
UPGRADE_INSTALL_DIR=upgrade_install

eval $(python $CHROMA_DIR/tests/utils/json_cfg2sh.py "$CLUSTER_CONFIG")

TESTS_DIR="tests/integration/installation_and_upgrade/"

trap "set +e; echo 'Collecting reports...'; scp root@$TEST_RUNNER:~/test_report*.xml \"$PWD/test_reports/\"" EXIT

# Install and setup chroma software storage appliances
pdsh -l root -R ssh -S -w $(spacelist_to_commalist ${STORAGE_APPLIANCES[@]}) "exec 2>&1; set -xe
# Ensure that coverage is disabled
# https://github.com/pypa/virtualenv/issues/355
python_version=\$(python -c 'import platform; print \".\".join(platform.python_version_tuple()[0:2])')
rm -f /usr/lib/python\$python_version/site-packages/sitecustomize.py*

if $USE_FENCE_XVM; then
    # fence_xvm support
    mkdir -p /etc/cluster
    echo \"not secure\" > /etc/cluster/fence_xvm.key
fi" | dshbak -c
if [ ${PIPESTATUS[0]} != 0 ]; then
    exit 1
fi

if ${UPGRADE_FROM_3:-false}; then
    # first fetch and install chroma 3.1.1.0
    BUILD_JOB=ieel-b3_1
    BUILD_NUM=427
    set +x # don't remove this line lest you leak confidential information
    . ~/auth.sh
    cat <<"EOF"
++ curl -s -k 'https://jenkins-pull:********@jenkins-old.lotus.hpdd.lab.intel.com:8080/job/ieel-b3_1/427/api/xml?xpath=*/artifact/fileName&wrapper=foo'
++ sed -e 's/.*>\\([i]\\?ee[l]\\?-[0-9\\.][0-9\\.]*.tar.gz\\)<.*/\\1/'
EOF
    IEEL_FROM_ARCHIVE=$(curl -s -k "https://jenkins-pull:${OLDJENKINS_PULL}@jenkins-old.lotus.hpdd.lab.intel.com:8080/job/$BUILD_JOB/$BUILD_NUM/api/xml?xpath=*/artifact/fileName&wrapper=foo" | sed -e 's/.*>\([i]\?ee[l]\?-[0-9\.][0-9\.]*.tar.gz\)<.*/\1/')
    echo "+ IEEL_FROM_ARCHIVE=$IEEL_FROM_ARCHIVE"
    set -x
    IEEL_FROM_VER="${IEEL_FROM_ARCHIVE#*-}"
    IEEL_FROM_VER="${IEEL_FROM_VER%.tar.gz}"

    if [ ! -f "$IEEL_FROM_ARCHIVE" ]; then
        set +x # don't remove this line lest you leak confidential information
        cat <<EOF
+ curl -k -O https://jenkins-pull:********@jenkins-old.lotus.hpdd.lab.intel.com:8080/job/$BUILD_JOB/$BUILD_NUM/artifact/$IEEL_FROM_ARCHIVE
EOF
        curl -k -O "https://jenkins-pull:${OLDJENKINS_PULL}@jenkins-old.lotus.hpdd.lab.intel.com:8080/job/$BUILD_JOB/$BUILD_NUM/artifact/$IEEL_FROM_ARCHIVE"
        set -x
    fi
else
    # first fetch and install IML 4.0.4
    # starting with 4.0.5 might leave us with no not have anything to
    # upgrade which will fail the upgrade test as it expects that there
    # should always be an upgrade available
    BUILD_JOB=ieel
    BUILD_NUM=3511
    IEEL_FROM_ARCHIVE=$(curl -s -k "http://jenkins.lotus.hpdd.lab.intel.com/job/$BUILD_JOB/$BUILD_NUM/api/xml?xpath=*/artifact/fileName&wrapper=foo" | sed -re 's/.*>(([i]\?ee[l]\?|iml)-[0-9\.][0-9\.]*.tar.gz)<.*/\1/')
    IEEL_FROM_VER="${IEEL_FROM_ARCHIVE#*-}"
    IEEL_FROM_VER="${IEEL_FROM_VER%.tar.gz}"

    if [ ! -f "$IEEL_FROM_ARCHIVE" ]; then
        curl -k -O "http://jenkins.lotus.hpdd.lab.intel.com/job/$BUILD_JOB/$BUILD_NUM/artifact/$IEEL_FROM_ARCHIVE"
    fi
fi

if ${UPGRADE_FROM_3:-false}; then
    EXPECT_SCRIPT=install-3.x.exp
else
    EXPECT_SCRIPT=install.exp
fi
# Install and setup old manager
scp $IEEL_FROM_ARCHIVE $CHROMA_DIR/tests/utils/"$EXPECT_SCRIPT" root@$CHROMA_MANAGER:/tmp
ssh root@$CHROMA_MANAGER "#don't do this, it hangs the ssh up, when used with expect, for some reason: exec 2>&1
set -ex
yum -y install expect

# Unpack the previous install into /tmp/$PREVIOUS_INSTALL_DIR
cd /tmp
mkdir $PREVIOUS_INSTALL_DIR
mv $IEEL_FROM_ARCHIVE $PREVIOUS_INSTALL_DIR/$IEEL_FROM_ARCHIVE
mv $EXPECT_SCRIPT $PREVIOUS_INSTALL_DIR/

cd $PREVIOUS_INSTALL_DIR
tar xzvf $IEEL_FROM_ARCHIVE

# Install from the installation package
cd ${IEEL_FROM_ARCHIVE%%.tar.gz}
if ! expect ../$EXPECT_SCRIPT $CHROMA_USER $CHROMA_EMAIL $CHROMA_PASS ${CHROMA_NTP_SERVER:-localhost}; then
    rc=\${PIPESTATUS[0]}
    echo \"Install log:\"
    cat /var/log/chroma/install.log
    exit \$rc
fi
# make some compatibilty links for older versions of RHEL
# this is most likely a product gap
ln -s 7 /var/lib/chroma/repo/iml-agent/7.5
ln -s 7 /var/lib/chroma/repo/iml-agent/7.4
ln -s 7 /var/lib/chroma/repo/iml-agent/7.3
rpm -qa | sort > /tmp/rpms_before_upgrade"
if [ ${PIPESTATUS[0]} != 0 ]; then
    exit 1
fi

# Install and setup chroma software storage appliances
pdsh -l root -R ssh -S -w $(spacelist_to_commalist ${STORAGE_APPLIANCES[@]}) "exec 2>&1; set -xe
# let's see what's in yum.conf at this point
cat /etc/yum.conf
if grep  ^distroverpkg= /etc/yum.conf; then
    # and fix it if necessary
    RH_RELEASE=\$(rpm -q --whatprovides redhat-release)
    ed <<EOF /etc/yum.conf
/distroverpkg=/c
distroverpkg=\${RH_RELEASE%-*-*}
.
wq
EOF
fi" | dshbak -c
if [ ${PIPESTATUS[0]} != 0 ]; then
    exit 1
fi

# Install a client
source $CHROMA_DIR/tests/framework/integration/utils/install_client.sh
wait_for_nodes "$CLIENT_1" "rpm -q kmod-lustre-client || exit 0
[ \$(uname -r) = \$(grubby --default-kernel | sed -e 's/.*z-//') ]"

echo "Create and exercise a filesystem..."

TESTS="$TESTS_DIR/../shared_storage_configuration/test_cluster_setup.py \
       $TESTS_DIR/test_update_with_yum.py:TestYumUpdate.test_clean_linux_devices \
       $TESTS_DIR/test_create_filesystem.py:TestCreateFilesystem.test_create"

# shellcheck disable=SC2086
ssh root@$TEST_RUNNER "exec 2>&1; set -xe
cd /usr/share/chroma-manager/
unset http_proxy; unset https_proxy
export UPGRADE_FROM_3=$UPGRADE_FROM_3
./tests/integration/run_tests -f -c /root/cluster_cfg.json -x ~/test_report_pre_upgrade.xml $TESTS"

echo "Now upgrade the OS and IML..."

# first have to shut down the filesystem so that we don't have incompatible OS/IML issues
ssh root@$TEST_RUNNER "exec 2>&1; set -xe
cd /usr/share/chroma-manager/
unset http_proxy; unset https_proxy
export UPGRADE_FROM_3=$UPGRADE_FROM_3
./tests/integration/run_tests -f -c /root/cluster_cfg.json -x ~/test_report_post_filesystem_stop.xml $TESTS_DIR/test_update_with_yum.py:TestYumUpdate.test_stop_before_update"

. $CHROMA_DIR/tests/framework/integration/utils/upgrade_os.sh
if ! upgrade_os $TEST_DISTRO_NAME $UPGRADE_DISTRO_VERSION $(spacelist_to_commalist $CHROMA_MANAGER ${STORAGE_APPLIANCES[@]} ${WORKERS[@]}); then
    echo "Upgrade failed"
    exit 1
fi

# re-enable needed repos needed for the upgraded version
pdsh -l root -R ssh -S -w $(spacelist_to_commalist $CHROMA_MANAGER ${STORAGE_APPLIANCES[@]} ${WORKERS[@]}) "exec 2>&1; set -xe
yum-config-manager --enable addon-epel\$(rpm --eval %rhel)-x86_64
yum-config-manager --enable $COPR_OWNER-$COPR_PROJECT
yum-config-manager --enable mirror.centos.org_centos_7_extras_x86_64_" | dshbak -c
if [ ${PIPESTATUS[0]} != 0 ]; then
    exit 1
fi

if [ -f ~/storage_server.repo.in ]; then
    STORAGE_SERVER_REPO=~/storage_server.repo.in
fi

if ! ${UPGRADE_FROM_3:-false}; then
    # need to get the additional storage server repos on the agent
    # nodes *BEFORE* the upgrade so that when the upgrade completes
    # and the sessions to the agent are re-established, the agent
    # already has access to the needed additional repos
    # this also simulates the state of the MFL repo when the upgrade
    # will be done in production
    pdsh -l root -R ssh -S -w "$(spacelist_to_commalist "${STORAGE_APPLIANCES[@]}")" \
        "exec 2>&1; set -xe
    # add any repos required by this test run
    if [ -n \"$STORAGE_SERVER_REPOS\" ]; then
        for repo in $STORAGE_SERVER_REPOS; do
            curl \"\$repo\" >> /etc/yum.repos.d/Intel-Lustre-Agent.repo
        done
    fi" | dshbak -c
    if [ "${PIPESTATUS[0]}" != "0" ]; then
        exit 1
    fi
fi

# Install and setup manager
ARCHIVE_SUFFIX=.tar.gz
if $JENKINS; then
    ARCHIVE_PATH=.
    ARCHIVE_SUFFIX="-current$ARCHIVE_SUFFIX"
else
    ARCHIVE_PATH=chroma-bundles
    ARCHIVE_NAME=$SHORT_ARCHIVE_NAME-$IEEL_VERSION.tar.gz
fi
scp $STORAGE_SERVER_REPO "$ARCHIVE_PATH/$ARCHIVE_NAME" "$CHROMA_DIR"/tests/utils/upgrade.exp root@"$CHROMA_MANAGER":/tmp
ssh root@"$CHROMA_MANAGER" "#don't do this, it hangs the ssh up, when used with expect, for some reason: exec 2>&1
set -ex
existing_IML_version=\$(rpm -q --qf \"%{VERSION}-%{RELEASE}\n\" chroma-manager)

# Unpack the current install into /tmp/$UPGRADE_INSTALL_DIR
cd /tmp
mkdir $UPGRADE_INSTALL_DIR
mv $ARCHIVE_NAME $UPGRADE_INSTALL_DIR/$ARCHIVE_NAME
mv upgrade.exp $UPGRADE_INSTALL_DIR/upgrade.exp

cd $UPGRADE_INSTALL_DIR
tar xzvf $ARCHIVE_NAME
cd \"${ARCHIVE_NAME%$ARCHIVE_SUFFIX}\"

# Install from the installation package
echo \"First without access to YUM repos\"

yum -y install bind-utils

iptables_remove=\$(mktemp)
trap 'bash -ex \"\$iptables_remove\"; rm \"\$iptables_remove\"' EXIT

grep -e ^base -e ^mirror /etc/yum.repos.d/* | \
    sed -e 's/.*=\(.*\):\/\/\([^/]*\)\/.*/\1 \2/' -e 's/\(.*\):\(.*\)/\1 \2/' | sort -u | \
while read method host port; do
    if [ \"\$method\" = \"file\" ]; then
        continue
    fi
    if [ -z \"\$port\" ]; then
        case \$method in
             http)   port=80  ;;
            https)   port=443 ;;
        esac
    fi
    host \$host | sed -ne '/has address/s/.* //p' -e '/:/d' | \
    while read ip; do
        iptables -I OUTPUT -d \$ip -p tcp --dport \$port -j REJECT
        echo \"iptables -D OUTPUT -d \$ip -p tcp --dport \$port -j REJECT\" >> \"\$iptables_remove\"
    done
done

if expect ../upgrade.exp; then
    echo \"Installation unexpectedly succeeded without access to repos\"
    iptables -L -nv
    exit 1
fi

bash -ex \"\$iptables_remove\"
rm \"\$iptables_remove\"
trap '' EXIT

if $RHEL; then
    release=\$(lsb_release -sr || sed -n -e '1s/.* release \(.*\) .*/\1/p' /etc/issue)
    yum-config-manager --disable  rhel-\$(rpm --eval %rhel)-server-optional-rpms,RHEL-\$release-optional-x86_64
    # let's also remove any local RH optional repo
    if grep \"RHEL-\$(rpm --eval %rhel)\.[0-9]-optional-x86_64\" /etc/yum.repos.d/cobbler-config.repo; then
        ed <<\"EOF\" /etc/yum.repos.d/cobbler-config.repo
/\[RHEL-\$(rpm --eval %rhel)\.[0-9]-optional-x86_64\]/;/^$/d
wq
EOF
    fi
fi

if ! expect ../upgrade.exp; then
    rc=\${PIPESTATUS[0]}
    echo \"Install log:\"
    cat /var/log/chroma/install.log
    exit \$rc
fi
# make some compatibilty links for older versions of RHEL
# this is most likely a product gap
ln -s 7 /var/lib/chroma/repo/iml-agent/7.5
ln -s 7 /var/lib/chroma/repo/iml-agent/7.4
ln -s 7 /var/lib/chroma/repo/iml-agent/7.3

# make sure it really did do an upgrade
upgraded_IML_version=\$(rpm -q --qf \"%{VERSION}-%{RELEASE}\n\" chroma-manager)
if [ \$existing_IML_version = \$upgraded_IML_version ]; then
    echo \"Upgrade didn't actually upgrade the chroma-manager package\"
    echo \"Install log:\"
    cat /var/log/chroma/install.log
    exit 1
fi

if [[ $TEST_DISTRO_VERSION =~ 6.* ]]; then
    # install cman here to test that the fence-agents-iml package is being a
    # duck-like replacement for fence-agents since cman depends on
    # fence-agents
    yum -y install cman
fi

cat <<\"EOF1\" > /usr/share/chroma-manager/local_settings.py
import logging
LOG_LEVEL = logging.DEBUG
$LOCAL_SETTINGS
EOF1

# override /usr/share/chroma-manager/storage_server.repo
if [ -f /tmp/storage_server.repo.in ]; then
    # make sure we use the correct lustre though!
    sed -e \"s/@LUSTRE_SERVER_URL@/${LUSTRE_SERVER_URL//\//\\\\/}/\" \
        -e \"s/@LUSTRE_CLIENT_URL@/${LUSTRE_CLIENT_URL//\//\\\\/}/\" \
        < /tmp/storage_server.repo.in > /usr/share/chroma-manager/storage_server.repo
fi
# add any repos needed by the test
if [ -n \"$STORAGE_SERVER_REPOS\" ]; then
    for repo in $STORAGE_SERVER_REPOS; do
        {
            echo
            curl \"\$repo\"
        } >> /usr/share/chroma-manager/storage_server.repo
    done
fi

# Ensure that coverage is disabled
# https://github.com/pypa/virtualenv/issues/355
python_version=\$(python -c 'import platform; print \".\".join(platform.python_version_tuple()[0:2])')
rm -f /usr/lib/python\$python_version/site-packages/sitecustomize.py*"

if ${UPGRADE_FROM_3:-false}; then
    # the manual bits that need to be done for 3.x to 4.x upgrades
    # see https://github.com/whamcloud/integrated-manager-for-lustre/issues/125
    # updated per https://github.com/whamcloud/Online-Help/pull/54
    pdsh -l root -R ssh -S -w $(spacelist_to_commalist ${STORAGE_APPLIANCES[@]}) "exec 2>&1; set -xe
    yum -y install pdsh" | dshbak -c
    if [ ${PIPESTATUS[0]} != 0 ]; then
        exit 1
    fi

    ssh root@"$CHROMA_MANAGER" "exec 2>&1; set -xe
    yum -y install pdsh
    pdcp -l root -R ssh -w $(spacelist_to_commalist "${STORAGE_APPLIANCES[@]}") /usr/share/chroma-manager/storage_server.repo /etc/yum.repos.d/Intel-Lustre-Agent.repo"

    pdsh -l root -R ssh -S -w "$(spacelist_to_commalist "${STORAGE_APPLIANCES[@]}")" "exec 2>&1; set -xe

    # TODO: we really just need to adjust cache timeouts here to account for
    #       our compressed timelines
    yum clean all

    yum -y upgrade chroma-agent\*

    systemctl stop zed
    rmmod zfs zcommon znvpair spl

    yum erase -y zfs-dkms spl-dkms lustre lustre-modules lustre-osd-ldiskfs \
    lustre-osd-zfs lustre-osd-ldiskfs-mount lustre-osd-zfs-mount libzpool2 libzfs2

    #TODO: if we install the new kernel here and reboot, then continue
    #on with the below, we should only build dkms modules once instead
    #of twice

    yum -y --nogpgcheck install lustre-ldiskfs-zfs kernel-devel-\*_lustre
    grubby --default-kernel
    $REBOOT_NODE" | dshbak -c
    if [ "${PIPESTATUS[0]}" != "0" ]; then
        exit 1
    fi

    # the second argumant closes a race where we check a node
    # before it's even been shut down
    wait_for_nodes "${STORAGE_APPLIANCES[*]}" "[ \$(uname -r) = \$(grubby --default-kernel | sed -e 's/.*z-//') ]"

    # give the choma agent time to start up and create a session
    # without this we get:
    # [2017-11-04 07:38:06,720: ERROR/job_scheduler] Job 83 step 0 encountered an agent error: Communications error with vm5 because session terminated
    # from the next test to run.
    # should we really have to wait externally here or should
    # agent <-> management communications be taking care of this for us?

    sleep 60
fi
echo "End upgrade and setup."

echo "Test existing filesystem is still there"

TESTS="$TESTS_DIR/test_data_consistancy.py \
       $TESTS_DIR/test_update_with_yum.py:TestYumUpdate.test_obsolete_chroma_diagnostics \
       $TESTS_DIR/test_update_with_yum.py:TestYumUpdate.test_yum_update \
       $TESTS_DIR/test_create_filesystem.py:TestExistsFilesystem.test_exists"

ssh root@$TEST_RUNNER "exec 2>&1; set -xe
cd /usr/share/chroma-manager/
unset http_proxy; unset https_proxy
export UPGRADE_FROM_3=$UPGRADE_FROM_3
export UPGRADE_FROM_VER=$IEEL_FROM_VER
./tests/integration/run_tests -f -c /root/cluster_cfg.json -x ~/test_report_post_upgrade.xml $TESTS"

# now provide an information inventory of the difference in the RPM
# catalog after the upgrade

pdsh -l root -R ssh -S -w "$(spacelist_to_commalist "$ALL_NODES")" "exec 2>&1; set -xe
if [ -f /tmp/rpms_before_upgrade ]; then
    if ! diff -W 120 -y /tmp/rpms_before_upgrade <(rpm -qa | sort); then
        diff_rc=${PIPESTATUS[0]}
        # diff exits with 1 if differences are found
        if [ \"\$diff_rc\" -ne 1 ]; then
            exit \"\$diff_rc\"
        fi
    fi
    rm /tmp/rpms_before_upgrade
fi" | dshbak -c
if [ ${PIPESTATUS[0]} != 0 ]; then
    exit 1
fi

# test that removing the chroma-manager RPM removes /var/lib/chroma
ssh root@$CHROMA_MANAGER "set -xe
exec 2>&1
ls -l /var/lib/chroma
rpm -e chroma-manager-cli chroma-manager chroma-manager-libs
if [ -d /var/lib/chroma ]; then
    echo \"Removing RPMs failed to clean up /var/lib/chroma\"
    ls -l /var/lib/chroma
    exit 1
fi"

exit 0
